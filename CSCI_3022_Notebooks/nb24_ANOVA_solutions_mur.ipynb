{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 24: One-Way Analysis of Variance (ANOVA) Solutions\n",
    "***\n",
    "\n",
    "We'll need Numpy, Matplotlib, Pandas, and scipy.stats for this notebook, so let's load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy import stats\n",
    "import statsmodels.api as sm \n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 - Diet, Exercise, and Weight Loss \n",
    "*** \n",
    "\n",
    "A randomized control study was performed with $9$ subjects to investigate the effect of exercise and diet on weight loss.  All $9$ subjects of the study exercised on a daily basis, one third of the subjects ate their regular diet, one third of subjects ate based on Diet $A$, and one third of subjects ate based on Diet $B$.  The observed weight loss after one week is summarized in the following data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Control</th>\n",
       "      <th>Diet A</th>\n",
       "      <th>Diet B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Control  Diet A  Diet B\n",
       "0        3       5       5\n",
       "1        2       3       6\n",
       "2        1       4       7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfD = pd.DataFrame({\"Control\": [3, 2, 1], \"Diet A\": [5, 3, 4], \"Diet B\": [5, 6, 7] })\n",
    "dfD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: We're interested in determining whether the mean weight-loss of all three groups are the same, or if some groups have better results.  We've done this example by hand in class.  In this exercise you'll use [scipy.stats.f_oneway](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html) function to verify our results. Check out the docs, then use the function to find the appropriate $F$-statistic and corresponding p-value for the ANOVA test. Does the test indicate, at the $\\alpha = 0.05$ significance level, that the mean weight-loss across all groups is the same?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = 12.00000\n",
      "pval = 0.00800\n",
      "The critical F value is 5.1433\n"
     ]
    }
   ],
   "source": [
    "# stats.f_oneway returns 2 parameters from the groups of data: F-score and p-value of F.\n",
    "F, pval = stats.f_oneway(dfD[\"Control\"], dfD[\"Diet A\"], dfD[\"Diet B\"])\n",
    "\n",
    "# Print out the F-score and the corresponding p-value.\n",
    "print(\"F = {:.5f}\".format(F))\n",
    "print(\"pval = {:.5f}\".format(pval))\n",
    "\n",
    "# Find the critical F. \n",
    "# Recall the df of numerator is k-1=3-1=2 and df of denominator is N-k=9-3=6.\n",
    "F_cr = stats.f.ppf(.95,2,6)\n",
    "\n",
    "# Print the critical F-value.\n",
    "print(\"The critical F value is {:.5}\".format(F_cr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $0.008 < \\alpha = 0.05$ we conclude that $\\color{red}{\\text{at least one of the group means is different}}$ from the others.\n",
    "\n",
    "Also, the F-score is greater than the critical F. i.e.  $12>5.14$, so again, we reject the null and say, $\\color{red}{\\text{at least one of the group means is different}}$ from the others.\n",
    "\n",
    "Note: Remember the F-score and p-value: 12.0 and .008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: In class, we claimed that an ANOVA $F$-test is equivalent to linear regression where the features are binary categorical variables associated with group membership. In this exercise we'll verify this.\n",
    "\n",
    "The following code re-factors the DataFrame to create binary categorical variables corresponding to Diet $A$ and Diet $B$.  Look at the resulting DataFrame, and explain how the response and features are encoded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': array([3, 2, 1, 5, 3, 4, 5, 6, 7], dtype=int64), 'Diet A': array([0., 0., 0., 1., 1., 1., 0., 0., 0.]), 'Diet B': array([0., 0., 0., 0., 0., 0., 1., 1., 1.])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>Diet A</th>\n",
       "      <th>Diet B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss  Diet A  Diet B\n",
       "0     3     0.0     0.0\n",
       "1     2     0.0     0.0\n",
       "2     1     0.0     0.0\n",
       "3     5     1.0     0.0\n",
       "4     3     1.0     0.0\n",
       "5     4     1.0     0.0\n",
       "6     5     0.0     1.0\n",
       "7     6     0.0     1.0\n",
       "8     7     0.0     1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create columns of the same data in order to analyze using MLR instead of ANOVA.\n",
    "\n",
    "y = dfD.values   # .values changes data format from pandas to numpy\n",
    "                 # So we have [3 5 5]\n",
    "                 #            [2 3 6]\n",
    "                 #            [1 4 7]\n",
    "y = y.T          # .T transposes the data. Rows become columns.\n",
    "                 # So, now we have [3 2 1]\n",
    "                 #                 [5 3 4]\n",
    "                 #                 [5 6 7]\n",
    "y = y.flatten()  # .flatten produces one continuous array from the rows.\n",
    "                 # So y is now the numpy array [3 2 1 5 3 4 5 6 7]\n",
    "                 # Or, [Control, Diet A, Diet B]\n",
    "\n",
    "# The same work could have been done in a single line of code as follows:\n",
    "#y = dfD.values.T.flatten()\n",
    "\n",
    "\n",
    "dct = {\"loss\": y}  # creates a single element dictionary. \n",
    "                   # One key, one value (the 'y' array).\n",
    "                   # dct is now {'loss': array([3, 2, 1, 5, 3, 4, 5, 6, 7])}\n",
    "\n",
    "# Create an empty array called 'counts'\n",
    "counts = []\n",
    "\n",
    "# This for-loop fills 'counts' with the lengths of the original data frames columns.\n",
    "# The column entitled 'control' contained 3 pieces of data.\n",
    "# The column entitled 'Diet A' contained 3 pieces of data.\n",
    "# The column entitled 'Diet B' contained 3 pieces of data.\n",
    "for column in dfD.columns:    # .columns cycles thru the headers of the dataframe\n",
    "    count = len(dfD[column])  # The length of each column is stored in array 'count'\n",
    "    counts.append(count)      # counts is now [3 3 3]\n",
    "\n",
    "# Create an empty array called 'ccf'\n",
    "ccf = []                            # cumulative count function\n",
    "\n",
    "# 'num_cols' contains the number of columns of the original dataframe, i.e. 3.\n",
    "num_cols = len(dfD.columns)         # .columns returns header names of dataframe\n",
    "\n",
    "# This for-loop fills 'ccf' with cumulative values from 'counts=[3,3,3]'.\n",
    "for ii in range(1,num_cols+1):      # loop runs for 1, 2, 3\n",
    "    val = int(np.sum(counts[:ii]))  # 'counts' is [3, 3, 3]. iterations: 3, 3+3, 3+3+3\n",
    "    ccf.append(val)                 # ccf goes from [3] to [3, 6] to [3, 6, 9]\n",
    "\n",
    "# This for-loop runs 2 times, once for ii=1 and once for ii=2.\n",
    "for ii in range(1,num_cols):    # num_cols holds the value 3 since there are 3 headers\n",
    "    x = np.zeros(len(y))        # 'y' holds the 9 weight loss values. 'x' is 9 zero's.\n",
    "    x[ccf[ii-1]:ccf[ii]] = 1    # first iteration from 3 to 6. Second iteration, 6 to 9.\n",
    "                                   # First iteration, x[3:6] filled with '1'.\n",
    "                                       # [0 0 0 1 1 1 0 0 0]\n",
    "                                   # Second iteration, x[6:9] filled with '1'.\n",
    "                                       # [0 0 0 0 0 0 1 1 1]\n",
    "    dct[dfD.columns[ii]] = x    # recall dct is a single element (key:value) dictionary.\n",
    "                                # creating new key for dictionary.\n",
    "                                # New key has header from dataframe dfD.\n",
    "                                # The new key was called with columns[ii]         \n",
    "\n",
    "print(dct)                      # get a visual of the dictionary created.\n",
    "dfR = pd.DataFrame(dct)         # creating a new df with the dictionary input\n",
    "dfR.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the Control column as the control group (duh).  The binary features $X_1$ and $X_2$ correspond to the Diet $A$ and Diet $B$ groups, respectively.  The first three responses correspond to the control group, so both $X_1$ and $X_2$ are zero.  The next three responses correspond to Diet $A$ so $X_1 = 1$ and $X_2 = 0$.  Finally, the last three responses correspond to Diet $B$ so $X_1 = 0$ and $X_2 = 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Use statsmodels to $\\color{red}{\\text{perform a multiple linear regression on the data}}$ created in **Part B**.  Look at the model summary and compare the computed $F$-test and model coefficients to the results above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n",
      "C:\\Users\\julia\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:1541: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=9\n",
      "  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>loss</td>       <th>  R-squared:         </th> <td>   0.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 05 Dec 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:30:13</td>     <th>  Log-Likelihood:    </th> <td> -10.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     9</td>      <th>  AIC:               </th> <td>   27.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     6</td>      <th>  BIC:               </th> <td>   28.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td>    2.0000</td> <td>    0.577</td> <td>    3.464</td> <td> 0.013</td> <td>    0.587</td> <td>    3.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diet A</th> <td>    2.0000</td> <td>    0.816</td> <td>    2.449</td> <td> 0.050</td> <td>    0.002</td> <td>    3.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Diet B</th> <td>    4.0000</td> <td>    0.816</td> <td>    4.899</td> <td> 0.003</td> <td>    2.002</td> <td>    5.998</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.380</td> <th>  Durbin-Watson:     </th> <td>   2.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.304</td> <th>  Jarque-Bera (JB):  </th> <td>   0.844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.000</td> <th>  Prob(JB):          </th> <td>   0.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.500</td> <th>  Cond. No.          </th> <td>    3.73</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   loss   R-squared:                       0.800\n",
       "Model:                            OLS   Adj. R-squared:                  0.733\n",
       "Method:                 Least Squares   F-statistic:                     12.00\n",
       "Date:                Mon, 05 Dec 2022   Prob (F-statistic):            0.00800\n",
       "Time:                        13:30:13   Log-Likelihood:                -10.946\n",
       "No. Observations:                   9   AIC:                             27.89\n",
       "Df Residuals:                       6   BIC:                             28.48\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.0000      0.577      3.464      0.013       0.587       3.413\n",
       "Diet A         2.0000      0.816      2.449      0.050       0.002       3.998\n",
       "Diet B         4.0000      0.816      4.899      0.003       2.002       5.998\n",
       "==============================================================================\n",
       "Omnibus:                        2.380   Durbin-Watson:                   2.333\n",
       "Prob(Omnibus):                  0.304   Jarque-Bera (JB):                0.844\n",
       "Skew:                           0.000   Prob(JB):                        0.656\n",
       "Kurtosis:                       1.500   Cond. No.                         3.73\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dfR.loc[:,\"loss\"]                 # The dependent variable\n",
    "X = dfR.loc[:,[\"Diet A\", \"Diet B\"]]   # The predictors\n",
    "X = sm.add_constant(X)                # column of constants added for sm.OLS\n",
    "#print(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computed $F$-statistic and associated p-value for the MLR model are identical to those from the ANOVA model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Who's the Better Archer? \n",
    "*** \n",
    "\n",
    "Three friendly archery enthusiasts are arguing over which one is the superior archer.  Having taken Intro to Data Science, they decide to settle the bet by having a short competition and then performing a statistical analysis on the results.  In the competition, each archer takes 6 shots and records their score based on distance from the target (farther/higher is better).  The results are as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suzie</th>\n",
       "      <th>Jack</th>\n",
       "      <th>Ruth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Suzie  Jack  Ruth\n",
       "0      5     4     9\n",
       "1      4     8     8\n",
       "2      4     7     8\n",
       "3      3     5    10\n",
       "4      9     1     5\n",
       "5      4     5    10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfA = pd.DataFrame({\"Suzie\": np.array([5,4,4,3,9,4]),\"Jack\": np.array([4,8,7,5,1,5]),\"Ruth\": np.array([9,8,8,10,5,10])})\n",
    "dfA.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Use stats.f_oneway to perform an $F$-test to determine if the mean scores of the three archers are different at the $\\alpha = 0.05$ significance level.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The critical F is 3.6823\n",
      "F, pval = 5.00000, 0.02168\n"
     ]
    }
   ],
   "source": [
    "# Collect the F-score and the p-value from .f_oneway.\n",
    "F, pval = stats.f_oneway(dfA[\"Jack\"], dfA[\"Ruth\"], dfA[\"Suzie\"])\n",
    "\n",
    "# Just for fun, find the critical-F value, k-1 and N-k for df of num and denom.\n",
    "F_crt = stats.f.ppf(.95,3-1,18-3)\n",
    "print(\"The critical F is {:.5}\".format(F_crt))\n",
    "\n",
    "# Print the F-score and the p-value.\n",
    "print(\"F, pval = {:.5f}, {:.5f}\".format(F, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the p-value of the ANOVA test is $0.02168 < \\alpha = 0.05$ we reject the null hypothesis and conclude that there is at least one mean in the three groups that is different from the others.\n",
    "\n",
    "Alternatively, we also reject the null since the F-score = 5 > Critical-F = 3.68. We again note that at least one of the scores is different from the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use numpy to compute the $F$-statistic and associated p-value directly.  Verify that you get the same results as produced by stats.f_oneway.\n",
    "\n",
    "$SSW=\\sum_{k=1}^{q}\\sum_{j=1}^s(x_j-\\bar{x}_k)^2$\n",
    "\n",
    "$SSB=n\\cdot\\sum_{k=1}^g(\\bar{x}_k-\\bar{\\bar{x}})^2$\n",
    "\n",
    "$MSW = \\frac{SSW}{N-g}$\n",
    "\n",
    "$MSB = \\frac{SSB}{g-1}$\n",
    "\n",
    "$F=\\frac{MSB}{MSW}$\n",
    "\n",
    "$\\Large{F_{Critical} = F_{\\alpha,\\phantom{x} df_B,\\phantom{x} df_W}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSB, SSB_df = 46.778, 2\n",
      "SSW, SSW_df = 70.167, 15\n",
      "F, pval = 5.00000, 0.02168\n"
     ]
    }
   ],
   "source": [
    "# Get total number of points, which we will need in our calculations as seen above.\n",
    "# Get this number by changing the df to numpy (array), 'flatten' it, and find its length.\n",
    "N = len(dfA.values.flatten())   # pandas to numpy, continuous array\n",
    "  # This means N=18. All 18 scores.\n",
    "\n",
    "# Get total number of groups, again needed in the above calculations.\n",
    "I = len(dfA.columns)   # 'columns' returns the headers of the dataframe\n",
    "  # This means I=3. Suzie, Jack, Ruth\n",
    "    \n",
    "# Compute the grand_mean using .mean on all the 'values'.\n",
    "grand_mean = np.mean(dfA.values) \n",
    "\n",
    "# Compute the between-group sum of squares \n",
    "SSB = np.sum([dfA[col].count()*(dfA[col].mean()-grand_mean)**2 for col in dfA.columns])\n",
    "\n",
    "# Compute the between_group degrees of freedom \n",
    "SSB_df = I-1 \n",
    "\n",
    "# Compute the within-group sum of squares \n",
    "SSW = np.sum([np.sum((dfA[col] - dfA[col].mean())**2) for col in dfA.columns])\n",
    "\n",
    "# Compute the within_group degrees of freedom \n",
    "SSW_df = N-I \n",
    "\n",
    "# Compute the test statistic \n",
    "F = (SSB/SSB_df)/(SSW/SSW_df) \n",
    "\n",
    "# Compute the associated p-value \n",
    "pval = 1 - stats.f.cdf(F, SSB_df, SSW_df) \n",
    "\n",
    "# Print the results.\n",
    "print(\"SSB, SSB_df = {:.3f}, {}\".format(SSB, SSB_df))\n",
    "print(\"SSW, SSW_df = {:.3f}, {}\".format(SSW, SSW_df))\n",
    "print(\"F, pval = {:.5f}, {:.5f}\".format(F, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computed $F$-statistic and associated $p$-value are identical to those computed by stats.f_oneway. \n",
    "\n",
    "These (F and pval) are the same as given above using stats.f_oneway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: So, we see again that we should reject the null. This means that at least one of the archers has a score that is considered significantly different than their opponents. But how should they be ranked?\n",
    "\n",
    "Run the code below to use Tukey's Honest Significant Difference (HSD) test to determine which archers are statistically different using the [MultiComparison](http://www.statsmodels.org/dev/generated/statsmodels.sandbox.stats.multicomp.MultiComparison.html) module. Interpret the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import MultiComparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "  Jack   Ruth   3.3333 0.0435  0.0911  6.5755   True\n",
      "  Jack  Suzie  -0.1667    0.9 -3.4089  3.0755  False\n",
      "  Ruth  Suzie     -3.5 0.0337 -6.7422 -0.2578   True\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data = dfA.values.T.flatten()  # Pandas to NumPy, Transpose, and 'flatten'\n",
    "  # data = [5 4 4 3 9 4 4 8 7 5 1 5 9 8 8 10 5 10]\n",
    "\n",
    "# Create an empty array to hold the names of the archers.\n",
    "labels = []\n",
    "\n",
    "# This for-loop puts the archers name in once for each of their scores.\n",
    "# .count() is a built-in function that returns the number of times an object\n",
    "#  appears in a list. \n",
    "for col in dfA.columns:\n",
    "    labels = labels + [col]*dfA[col].count()\n",
    "  # labels = ['Suzie', 'Suzie', ...,'Jack', 'Jack', ...'Ruth', 'Ruth',...]\n",
    "  # Each 'name' 6 times.\n",
    "    \n",
    "mc = MultiComparison(data, labels)\n",
    "result = mc.tukeyhsd()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are three groups (corresponding to the three archers) we make $3$ pairwise comparisons.  The reject column tells us whether or not the null hypothesis that the two means are equal is rejected or not.  We see that there is sufficient statistical evidence to believe that Jack's and Ruth's means are different, Jack's and Suzie's means are **not** different, and Ruth's and Suzie's means are different. \n",
    "\n",
    "From this we can conclude that Jack's and Suzie's means are the same while Ruth's is different from the others.  Inspecting the sample means we observe that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suzie mean: 4.833\n",
      "Jack mean: 5.000\n",
      "Ruth mean: 8.333\n"
     ]
    }
   ],
   "source": [
    "print(\"Suzie mean: {:.3f}\".format(dfA[\"Suzie\"].mean()))\n",
    "print(\"Jack mean: {:.3f}\".format(dfA[\"Jack\"].mean()))\n",
    "print(\"Ruth mean: {:.3f}\".format(dfA[\"Ruth\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Ruth's sample mean is higher than the others we conclude that $\\mu_{Ruth} > \\mu_{Suzie} = \\mu_{Jack}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the example on schools from our notes on ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'schools.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30412/582726839.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfSchools\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"schools.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'schools.csv'"
     ]
    }
   ],
   "source": [
    "dfSchools = pd.read_csv(\"schools.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSchools.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the F-score and the p-value from .f_oneway.\n",
    "F, pval = stats.f_oneway(dfSchools[\"A\"], dfSchools[\"B\"], dfSchools[\"C\"])\n",
    "\n",
    "# Just for fun, find the critical-F value, k-1 and N-k for df of num and denom.\n",
    "F_crtl = stats.f.ppf(.95,3-1,30-3)\n",
    "print(\"The critical F is {:.5}\".format(F_crtl))\n",
    "\n",
    "# Print the F-score and the p-value.\n",
    "print(\"F, pval = {:.5f}, {:.5f}\".format(F, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = dfSchools.values.T.flatten()  # Pandas to NumPy, Transpose, and 'flatten'\n",
    "\n",
    "schoolNames = []\n",
    "\n",
    "for col in dfSchools.columns:\n",
    "    schoolNames = schoolNames + [col]*dfSchools[col].count()\n",
    "    \n",
    "mcSchool = MultiComparison(data2, schoolNames)\n",
    "result_S = mcSchool.tukeyhsd()\n",
    "\n",
    "print(result_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you decipher the comparisons?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"School A mean: {:.3f}\".format(dfSchools[\"A\"].mean()))\n",
    "print(\"School B mean: {:.3f}\".format(dfSchools[\"B\"].mean()))\n",
    "print(\"School C mean: {:.3f}\".format(dfSchools[\"C\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "School A and School B are not that different.\n",
    "\n",
    "School A and School C are not that different.\n",
    "\n",
    "School B and School C are statistically significantly different.\n",
    "\n",
    "The order, from low to high, is similar to:  $C$ then $A$ then $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.f.ppf(.95,2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
